<!DOCTYPE html>
<html lang="zh-CN">
<head>
	<link rel="stylesheet" href="layout.css">
	<script src="https://cdn.staticfile.net/twitter-bootstrap/5.1.1/js/bootstrap.min.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>智能的本质 - 文章详情</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <style>
p {
    font-size: 1.1em !important;
    line-height: 1.8;
    color: #2c3e50;
    margin-bottom: 1.5em;
    letter-spacing: 0.3px;
}

.source-block {
    background: linear-gradient(145deg, #ffffff 0%, #f8f9fa 100%);
    border-left: 4px solid #3498db;
    padding: 25px;
    margin: 30px 0;
    border-radius: 8px;
    box-shadow: 0 2px 15px rgba(0,0,0,0.05);
}

.source-title {
    color: #2c3e50;  
    margin: 0 0 15px 0;
    font-size: 18px;
    font-weight: 600;
}

.source-content {
    color: #34495e;
    font-size: 15px;
    line-height: 1.7;
}

.source-content a {
    color: #3498db;
    text-decoration: none;
    transition: all 0.3s ease;
}

.source-content a:hover {
    color: #2980b9;
    text-decoration: underline;
}

.article-container {
    max-width: 1000px;
    margin: 0 auto;
    padding: 40px;
    background: #fff;
    box-shadow: 0 0 30px rgba(0,0,0,0.03);
}

.article-header {
    text-align: center;
    margin-bottom: 60px;
    padding-bottom: 30px;
    border-bottom: 2px solid #f0f2f5;
}

.article-header h1 {
    color: #2c3e50;
    font-size: 2.5em;
    margin-bottom: 25px;
    line-height: 1.4;
}

.article-meta {
    color: #7f8c8d;
    font-size: 1em;
}

h2 {
    color: #2c3e50;
    font-size: 1.8em;
    margin: 2.5em 0 1.2em;
    padding-bottom: 0.6em;
    border-bottom: 2px solid #f0f2f5;
}

ul {
    color: #34495e;
    padding-left: 25px;
    margin: 1.2em 0;
}

ul li {
    margin-bottom: 1em;
    line-height: 1.7;
}

body {
    background-color: #fff;
    line-height: 1.8;
}


.article-content {
    padding: 0 15px;
}

@media (min-width: 768px) {
    .article-content {
        padding: 0 30px;
    }
}
    </style>
</head>
<body>
	 <header class="nav-area">
    <nav>
        <div class="logo">个人AI知识库</div>
        <ul class="nav-links">
            <li><a href="index01.html">首页</a></li>
            <li><a href="index02.html">关于</a></li>
            <li><a href="index03.html">资源</a></li>
            <li><a href="#contact">更多</a></li>
        </ul>
    </nav>
    <div class="article-container">
        <a href="index03.html" class="back-button">
            <i class="fas fa-arrow-left"></i> 返回上一页
        </a>
        
        <article>
            <div class="article-header">
                <h1><i class="fas fa-graduation-cap"></i> 智能的本质：人工智能与人类智能</h1>
                <div class="article-meta">
                    <span><i class="far fa-calendar-alt"></i> 发布日期：2024年12月</span>
                </div>
            </div>
   <div class="source-block">
    <h3 class="source-title">文章来源:知乎</h3>
    <div class="source-content">
        <p>原文链接: <a href="https://zhuanlan.zhihu.com/p/269284598" target="_blank">智能的本质：人工智能与人类智能</a></p>
            <div class="article-content">
            <p>本文，首先将会从算力、逻辑、结构、数据、概率等诸多层面，深入浅出地揭示智能的来源与运作，然后会结合生物演化与物理规律，给出一个从宏观到微观的洞见，很好地解释了智能的本质，最后还会从几个不同的层面，去看待智能与我们、及演化之间的关系。</p>

<p>相信本文的观点和视角，将会让我们更加清晰地理解智能，以及更加深入地理解我们自身的智能。</p>
<h2>主题目录</h2>
            <ul>
                <li>智能与算力</li>
                <li>智能与逻辑</li>
                <li>智能与结构</li>
                <li>智能与数据</li>
                <li>智能与概率</li>
                <li>智能的本质</li>
                <li>不同的视角</li>
                <li>智能的涌现</li>
            </ul>

<h2>智能与算力</h2>
<p>算力，并不是产生智能的本质原因所在。</p>

<p>人脑的算力有限，却可以进行逻辑推理和自主学习，而目前计算机的算力，已经远远超过了人脑"无数"倍，却依然无法进行类似人脑的逻辑推理和自主学习。

<p>而在另一方面，虽然人类中的少数天才，相较于普通人，拥有极其强悍的心算记忆能力，但如果和计算机的计算存储能力相比，少数天才也必然是望尘莫及的。

<p>那么在人类之间，虽然每个人的智能存在个体差异性，但显然我们并不会，只使用计算能力这个单一指标，来衡量一个人的智能高低。
<p>因为，虽然高智能，会表现出高算力，如冯·诺依曼（John von Neumann）与拉马努金（Srinivasa Ramanujan），但也有很多其它情况，例如：
<p>算力正常，表现出高智能（如政治家和艺术家），
<p>智能正常，表现出高算力（如计算相关从业者），
<p>智能偏低，表现出高算力（如异常基因携带者）。
<p>可见，智能与算力有相关性，但绝不是计算能力产生了人类智能，或是计算能力的高低，决定了人类智能的高低。
<p>不过，有趣的是：在很多场景下，计算机不仅可以表现出智能，甚至可以显得比人类更有智能，而在另外一些场景，对于人类智能轻而易举的任务（如说谎、幽默、暗讽、隐喻、道德判断等），但对计算机来说，却是异常困难。换言之，计算机的智能表现，体现出了一个"智能悖论"，即：（对人类）困难的问题是简单的，（对人类）简单的问题是困难的。
<p>这是为什么呢？
<p>对此，我们需要从两个角度来看：首先为什么计算机会表现出智能，其次是计算机智能与人类智能有什么区别。
<p>不过这两个视角，最终可能会指向同一个问题，即：智能的本质是什么？

<h2>智能与逻辑</h2>
<p>虽然计算机，不能够进行逻辑推理和自主学习，但却可以进行逻辑运算（又称布尔运算）。
<p>其基本原理就在于：计算机通过逻辑门，来进行逻辑运算，从而就拥有了映射逻辑关系的能力。
<p>所谓逻辑门，就是一组基本的逻辑运算，包括了：
<p>0——是假。
<p>1——是真。
<p>非——真假互换。
<p>与——有一个假就是假。
<p>或——有一个真就是真。
<p>异或——有异为真，有同为假，类似连连看找到不同为真，否则为假。
<p>大于、等于、小于、大于等于、小于等于、不等于——成立为真，否则为假。
<p>比特位的加法就会用到——异或，如：1 + 0 = 1，0 + 0 = 0，1 + 1 = 0进位1，而获得这个进位，需要同时用到——与，如：1 + 0 = 0， 0 + 0 = 0，1 + 1 = 1，结果即进位。
<p>事实上，异或也是通过组合得到的，即：A异或B =（A或B）与（非（A与B））。
<p>以上就是最基本的逻辑门计算，通过组合它们，就可以实现任意复杂度的逻辑运算，而组合它们的方式，就是逻辑电路。
<p>所谓逻辑电路，简单来说就是指完成逻辑运算的电路。具体一些，就是指一种以二进制（0和1）为基础，来实现（离散）数字信号逻辑运算的电路。
<p>那么，在物理现实中，逻辑门由晶体管实现，逻辑电路由集成电路实现。
<p>其基本原理就在于：晶体管可以（通过物理元件的属性）实现开关控制，使得通过它们的电平信号，产生或高或低的结果，以此来代表逻辑上的"真"与"假"（即二进制当中的1和0），从而实现逻辑门的计算，进而集成电路就可以组合晶体管，实现任意复杂的逻辑电路。
<p>电平——是指在电路中，不同点在相同阻抗下，电量相对比值的对数，其中电量可以是电功率、电压、电流。可以理解成"水平"，有一个稳定水平，高于的是高电平，低于的是低电平。
<p>于是，计算机通过晶体管和集成电路，就拥有了逻辑关系的映射能力——这可以看成是，把抽象的逻辑关系，转换到了物理的逻辑电路上。
<p>其处理过程就是：接收数据、分析数据（利用逻辑关系）、得出结果，也就是经典的"输入-处理-输出"模型。
<p>需要指出的是，逻辑电路不仅可以分析数据，还可以通过执行逻辑来进行数据的存取，包括指令、地址、程序等等。
<p>例如，通过组合逻辑门构造一个锁存器（Latch）——它可以保持一个比特位的数值（即0或1）不变，也可以让一个比特位的数值改变——而组合锁存器就<p>可以构造寄存器或内存（RAM）——所以，内存也有运行频率，这是控制逻辑门的速度，即时钟速度（Clock Speed）。
<p>事实上，计算机的算力，就是来自于数百亿的晶体管，进行超高速控制逻辑门的结果，显然物理电路的物理属性，决定了高算力的必然。
<p>那么相比计算机，人脑的算力"弱鸡"，是因为逻辑判断的速度不够快，其根本原因在于：
<p>生物电路控制逻辑门的速度，远远不如物理电路，这可以理解为——电化学反应的速度落后于电物理反应，即：脑细胞构建的逻辑门结构（电突触与化学突触），其反应速度远不如物理元件构建的逻辑门结构。
<p>具体来说，有三个方面：
<p>第一，神经元放电依赖（钠钾钙氯）离子通��的开闭，这个过程速度缓慢，导致其放电频率大约只有每秒400次，而计算机物理元件的放电频率可高达每秒40亿次。
<p>第二，神经元的导电性差、绝缘性差、又容易漏电，所以电信号传递速度缓慢，大约只有每秒100米，而计算机设备的电信号，其传递速度可以接近光速，达到每秒3亿米。
<p>第三，神经元之间的信息传递，依赖化学突触，但电位差抵达化学突触，并不一定就会激发神经递质的释放（因素众多、机制复杂、条件多变，这其实就是神经元计算的过程），其平均释放概率只有30%左右，而计算机结构的数据传递是100%确定的。
但重要的是，逻辑推理与逻辑判断的速度无关，只与结构和数据有关。
<p>也就是说，逻辑门计算的快慢，并不影响逻辑推理的过程和结果，这个过程——就是数据经过逻辑门结构时的逻辑运算，这个结果——就是经过计算后的数据。
<p>对应地来看：
<p>计算机的结构——就是物理硬件结构，人脑的结构——就是神经网络结构，这两种结构均实现了逻辑门计算；
<p>前者的计算数据——是物理电信号，后者的计算数据——是生物电信号，这两种电信号均转化自环境数据与信息的输入；
<p>前者的输入数据——是来自物理设备（如键盘、鼠标、传感器），后者的输入信息——是来自生物设备（如眼睛、鼻子、耳朵）。
<p>需要指出的是，能被人脑处理的数据，就是信息，不能被处理的数据，就是无法感知，所以对人脑来说——环境数据就是环境信息，输入数据就是输入信息。
<p>那么，人脑的逻辑门计算，在宏观上就是使用"如果怎么样，就怎么样，否则怎么样"的条件判断——这个"如果"的真假，就是进行"与、或、非"等等的逻辑运算（可任意组合），那么在微观上就是——从输入信息、到脑细胞激活、到电化学反应、到兴奋电位（代表1）或抑制电位（代表0）。
<p>而脑细胞的连接方式——多个胞体的轴突（输出信息），可以连接到一个胞体的多个树突（接收信息）——就可以形成各种"神经逻辑门"，与物理逻辑门的原理一致，即：多个轴突的输入信息组合（抑制与兴奋的叠加），抵达某个阈值，才能激活某个胞体的信息处理及传递。
<p>例如，人脑的视觉系统，并不处理光点信息，而是处理光几何信息（如各种角度的长条、长方形等），其实现方式就是：多个感知光点的视觉细胞（轴突），连接到同一个脑细胞（树突），当这些"光点细胞"同时输入信息时（即感知到多个光点），对应脑细胞才有反应，而这些"光点细胞"的排列形状，就是视觉系统可以处理的光几何形状。
<p>需要指出的是，数学运算 = 逻辑运算 + 读写操作——而读写并没有逻辑（只有运动），如果没有逻辑运算，就会是没有逻辑的（大概率错误的）读写。
<p>例如，实现二进制加法的抽象过程是：读取数字，比较数字（逻辑运算）——如果是0，写入1，即完成了加法计算——如果是1，写入0，移动高位，写入1，即完成了进位计算——而有了加法基础，就可以实现其它的数学运算。
<p>可见，计算机可以同人脑一样，进行无差别的逻辑门计算，其底层支撑在于：如果说"0是关1是开"，那么计算机（CPU）与人脑，就都可以抽象地看成是一个复杂的——"开关网络"（Switching Network）。
<p>这个开关网络，即是逻辑门计算的物理模型（物理模型体现结构，数学模型体现关系），它可以由不同的介质来承载实现——这正是让计算机可以表现出智能的根本原因所在。
<p>而计算机智能明显受制于人类智能的原因，就在于：
<p>第一，逻辑推理中的数据，计算机需要依赖人类提供输入。
<p>第二，数据中的逻辑关系，计算机需要依赖人类分析描述。
<p>第三，逻辑门计算的过程，计算机需要依赖人类编程控制。
<p>那么，计算机可以抛弃人类的帮助，自行分析数据中的逻辑关系，并自动控制逻辑门计算的过程吗？
<p>换言之，计算机可以在逻辑门计算之上，构建出类似人类智能的智能吗？再换言之，人类智能在逻辑门计算之上，所具有的根本性的"质变"是什么呢？

<h2>智能与结构</h2>
<p>如前所述，逻辑推理取决于逻辑门结构与数据，算力只是逻辑门结构的特性，推理过程是逻辑门结构对数据的计算，推理结果是计算后的数据——其与计算前的数据具有逻辑关系。
<p>而计算机虽然拥有逻辑门结构，但推理过程需要人类智能提供——数据与算法，其中算法负责控制逻辑门结构，去完成对数据的计算，并得到结果。
<p>具体来说，算法由程序描述，程序被转化成指令，指令被硬件（逻辑门结构）执行，这就实现了数据的逻辑运算，而人类智能通过编程，就可以控制计算机完成逻辑推理。
<p>当然，算法（Algorithm）可以是一个更抽象的概念（与计算机无关），即是指解决问题的完整描述，由一系列准确可执行的步骤组成，其代表着解决问题的策略。
<p>在此我们会发现，人类智能可以构造算法，但计算机却不行，而算法才是逻辑推理的关键，那么这其中的奥秘是什么呢？
<p>答案就是，结构——事实上，人脑的结构是逻辑门结构的超集，在此基础之上，相比计算机物理硬件结构的简单固定，人脑结构具有极大的复杂性和极强的可塑性。
<p>对于复杂性，计算机的存储结构、传输结构与计算结构是独立分离的，但人脑神经网络结构，既是存储结构，也是计算结构，甚至还是传输结构。
<p>因此，数据与算法，会存在于同一个脑结构之中。
<p>具体来说，就是神经元细胞之间的几何关系、密度、数量，膜内外的成分、浓度、电位，以及电化学反应的过程（如神经递质的种类、比例、释放量），等等——都是一种信息的记录与计算，从而信息的形成、传递与处理就是共用神经元细胞的，于是信息在脑结构中，自然就会相互关联与影响。
<p>换言之，环境信息被人脑捕获之后，其"运动"的某种模式——如带电离子的流动、神经递质的扩散——就对应了算法，而这种物理意义上的"运动算法"，是意识运作的底层，不受意识的控制，其结果就包含了直觉与潜意识，而直觉可以看成是潜意识的计算。
<p>这里需要指出的是，信息与数据之间的关系，即：信息是从数据中提取的关系，同样的数据看到不同的关系，就是不同的理解，就会有不同的信息，可见信息是数据的简化抽象，即过滤了很多不同维度的关系——类比来看"数据-信息"就像"质量-能量"。
<p>那么显然，计算机结构并没有"运动"的特性，也没有数据存储处理"一体化"的特性，相反计算机的数据，是独立于其结构的——结构的改变（如规模、架构）不会影响数据，数据的改变（如数量、关联）不���影响结构——所以，计算机的数据可以无损复制到另一台计算机上，但人脑的信息就无法复制，除非重建相同的脑结构。
<p>最为关键的是，计算机的结构无法产生算法，也就是无法从数据中提取逻辑关系，也就是无法从数据中提取信息，因此计算机要求输入数据"自带信息"——这是如何做到的呢？
<p>首先，需要数据结构，它是一种描述数据关系的结构化数���，即关于数据的数据，称之为元数据。
<p>其次，需要代码算法，它是一种可执行的数据，用于控制硬件结构完成计算，包括��辑运算和读写操作，这两者可以实现数学运算。
<p>最后，代码算法的执行，将会把数据映射到数据结构，从而实现数据中逻辑关系的提取，也就是信息的提取。
<p>由此可见，计算机要求输入数据（含有数据结构和代码算法），既要有逻辑关系，也要有逻辑处理，而这些都被转移到了由人类智能来提供。

<p>对于可塑性，输入信息可以改变人脑神经网络结构本身（包括生物逻辑门），从而改变对输入信息的获取和处理，于是结构和信息之间就形成了"结构吸收信息，信息塑造结构"的相互作用，这就如同——河床（是结构）约束引导河流（信息），河流（是信息）冲刷塑造河床（结构）。

<p>事实上，抽象地来看，逻辑即是结构所固有的关系，不同的结构（或同样结构不同角度）有不同的关系就有不同的逻辑，而结构的改变即是逻辑的改变。例如，人在梦境中的想法逻辑，会与清醒时有很大的不同，这就是因为人脑神经网络在睡眠时的激活结构不同，这种结构的不同，就会产生不同的想法逻辑。因此，人脑可以捕获环境信息，接着分析学习其中的逻辑关系，然后（将逻辑）存储进动态的人脑神经网络（结构）中（比如经验与常识），并参与后续（环境信息）的逻辑处理，这即是自主学习的能力。
<p>可见，大脑的可塑性表明——大脑的结构决定了大脑的功能，即：无差别的单元，构建有差别的结构，形成不同的功能。
<p>那么对比人脑，计算机的结构固定，完全没有动态性和自组织性，转而只能依赖人类智能提供——数据结构与算法（数据结构 + 算法 = 程序），于是计算机智能也就无法进行——自主学习与自主推理了。
<p>简而言之，人类智能是因为人脑的结构非常复杂，而计算机的结构如此简单，其"智能表现"是把复杂算法都转移到了程序设计之上，也就是让人类智能来思考产生。
<p>综上可见，我们"自诩"的智能，其实就是来自于——复杂结构的动态性与自组织性，其功能就在于——从环境信息中建模映射真实世界的逻辑关系，继而可以准确地预测未来。
<p>当然，人脑结构中存储的都是——简化模型，而对这些颅内模型的计算与建模，就是由智能所主导的——认知计算与认知建模。
<p>有趣的是，人脑的认知模型不仅简化，其认知模式还偏好简化，但它（模型和模式）可以复杂——这是一种演化冗余的结果。
<p>而通俗地说，人脑结构——决定了晶体智力（取决于学习，如技能和技艺，不受衰老影响），神经运作——决定了流体智力（取决于基因，如记忆力和算力，随衰老减退），智能——则建立在晶体智力与流体智力之上。
<p>那么，计算机智能有没有办法，突破固定结构的局限性，从不同的演化路径去"模拟"出人类智能呢？

<h2>智能与数据</h2>
<p>如前所述，能够创造出算法是智能的关键所在，而在编程领域，著名程序员、开源软件运动的思想家、黑客文化的理论家——埃里克·雷蒙德（Eric Raymond），在《Unix编程艺术》中，有这样一个实践性的洞见——算法和数据结构有一个关系，即：
<p>数据结构越复杂（如哈希表），算法就可以越简单，数据结构越简单（如数组），那么算法就需要越复杂。
<p>例如，编程语言越是动态化（如Python、JS、Lua），就越容易构建复杂结构，用其编写算法也就越容易，相反编程语言越是静态化（如C、C++、Java），就越难以构建复杂结构，用其编写算法就困难，而编程语言的演化是越来越动态化（如C#）。
<p>其原理就在于，算法实现——是逻辑关系的"计算映射"，即动态地进行逻辑关系的转化；数据结构——是逻辑关系的"固化映射"，即将已经计算好的逻辑关系，存储在了结构之中。
<p>可见，算法比数据结构多出了计算的过程——前者需要根据逻辑关系进行逻辑运算，后者仅需要根据结构的逻辑关系直接读写——所以应用数据结构进行逻辑关系的转化，会更加高效。
<p>而人脑可以从环境信息中，提取数据结构并习得算法，最终将两者存储到脑结构之中——可见，"神经结构、数据结构、算法"三者之间可以互相转化，或说互相表征。
<p>表征——是指用信息描述某一事物的状态，即：信息符号可以代替某一事物本身。
<p>换言之，如果数据结构足够强大，它就可以充当复杂算法的功能，甚至可以替代复杂的神经结构。
<p>因此，计算机智能"拟人"（即模拟人脑）的一个途径，就是通过强化数据结构来模拟神经结构，以及弱化人类智能所提供的代码算法，转而使用结构去生成算法，而这就是目前人工智能的发展方向——以下使用"人工智能"来替代"计算机智能"。
<p>顺便一提的是，在现实中，一个东西的结构越复杂，它的功能就越丰富，可以说结构决定了功能，更或者说结构就是功能，而功能来自于算法的执行——所以，结构转化为功能，就意味着结构蕴含了算法。
<p>那么，问题就回到了，人工智能的数据结构从何而来呢？
<p>显然，"人工"二字已经说明，依然由人类智能来提供，只不过这不是一个针对具体问题的数据结构，而是一个模拟人脑神经网络的通用数据结构——它是对人脑结构的简化抽象，并由程序语言编程实现的数学模型（以矩阵为基础，想象黑客帝国的母体），可称之为"类脑数据结构"，更形象的描述是"类脑神经网络"。
<p>接下来，人类智能继续提供一种算法——机器学习算法（如深度学习、强化学习等等，每种又有不同的具体实现），这种算法可以通过拟合与计算，试图在海量的大数据中找到各种各样的算法——从而把特定的输入问题与输出结果对应起来——这相当于实现了一种可以创造算法的"算法"。

<p>大数据——是指拥有多维度信息的大量数据，也就是说，不仅数据量大，信息量也大，而"大量数据"，仅仅是数据量大，信息量却不大，甚至可能很少。概括来看，大数据有4个明显的特征，即：数据量大、多维度、完备性、和实时性。

<p>薄数据——是大数据中，那些可量化、可测量，但未必重要的数据。
<p>厚数据——是大数据中，那些不可量化、不可测量，但重要的数据。
<p>而将类脑数据结构与机器学习算法结合起来，就可以动态地自组织类脑数据结构（通过结构连接关系的权重），以存储算法创造的算法——于是人工智能就表现出了自主学习与自主推理。

<p>有趣的是，有一种机器学习算法（强化学习，Reinforcement Learning）与人脑多巴胺强化学习的机制是相一致的，即：

<p>概率来自权重（即历史权重决定了算法的概率计算），权重来自奖励，奖励来自行为，行为来自决策，决策来自奖励，奖励来自概率（即现实概率决定了奖励的最终获取）——这说明机器可以使用人脑相同的学习机制进行"自我学习"。

<p>那么，这里算法习得的权重（也称权值），其实就相当于人脑神经元之间的连接强度，通过数据反复地训练与调整，无论是机器还是人脑，最终都可以把输出结果逼近正确答案。

<p>而这个过程，可以完全用数学描述，就如图灵奖得主、卷积神经网络之父——杨立昆（Yann LeCun），在《科学之路》中，所说：

<p>"所谓的机器学习，就是机器进行尝试、犯错和自我调整的操作。学习就是逐步减少系统误差的过程。训练机器的过程就是调整参数的过程。……基于成本函数最小化的学习，是人工智能运作的关键要素。通过调整系统参数来降低成本函数，也就是降低实际输出与期望输出之间的平均误差。实际上，最小化成本函数和训练系统是一回事。"

<p>成本函数（Cost Function）——也称为"代价函数"或"损失函数"（Loss Function），那么显然令"成本、代价、损失"的函数最小化，就是学习的过程，也是学习的目的所在。换言之，杨立昆指出：
<p>"（人工智能）神经网络的连接体系结构，即各层神经元的组织、以及神经元之间的连接，是确定的。但是权重，即加权和的参数是不确定的，它们可以通过学习来确定。"

<p>事实上，早在1950年，图灵就阐述了类似这样的想法，著名传记作家——沃尔特·艾萨克森（Walter Isaacson），在《创新者》中指出：

<p>为了反驳"洛夫莱斯夫人的异议"，即埃达·洛夫莱斯认为分析机无法像人脑一样工作，图灵在论文中提出了一个极具独创性的观点，即：

<p>"机器也许可以进行学习，从而逐渐发展出自己的主动性，并掌握产生新想法的能力。……图灵提出了一种奖励和惩罚机制，它可以促使机器重复或者避免某些行为，最终这台机器将会培养出自己对于思考的概念。"

<p>由上可见，人工智能是在通过"输入数据、数据结构、学习算法"之间的相互转化，来形成"类人智能"的——也就是从数据中找到结构，再从结构中产生算法，最后将算法存入结构。

<p>值得一提的是，实践表明，人工智能模型可以通过数据训练，获得非常精准的预测能力，但这种预测能力不具有可解释性，即无法解释预测结果的形成路径。

<p>换言之，类脑数据结构（或说类脑神经网络）是一个——"黑盒模型"，如同人脑一样。

<p>那么，从此也可以看出，结构涌现智能的规律与力量——就如同化学中结构决定性质，物理中结构决定激发，程序中结构决定功能，语言中结构决定语义，等等——或许结构决定了一切，这被称为"结构主义"。

<p>例如，杨立昆在《科学之路》中，就指出："人类视觉系统，不仅受过对图像进行分类的训练，而且除了完成特定任务，它还接受过捕捉视觉世界结构的训练，……因此一个孩子不需要成千上万头大象，来学习「大象」的概念，而是只有三头就足够了，甚至在插图中描述出图案都可以。"

<p>而按此视角，"听不懂"、"不明白"、"搞不清"、"难理解"——其本质都是无法重现相同（或相似）的结构，即脑神经网络结构，如：动物听不懂人话，学渣不明白公式，平民搞不清政治，男人不理解女人。

<p>换个角度来看，一个人哪怕经验再丰富，与"大数据"相比也只是"小数据"，但"小数据"并不影响人脑具有强大的预测能力——其原因就在于，从有限的数据中获得（或说提取存储）有效有意义的结构，而"结构"可以预测未来。

<p>那么，如果拥有了足够大的"大数据"，这就像拥有了一张分辨率足够高的"照片"，任意放大"照片"的某个局部，都可以看到足够多的信息与连接，这就有更多的可能性，从这张"照片"里发现某些规律，即结构——这就是人工智能的路径与意义，即连接了数据与结构。

<p>然而除了数据结构，在类人智能的道路上，仍有一个显著的问题，即是人脑的模糊性与计算机的精确性，它们之间的差异性应该如何解决？

<h2>智能与概率</h2>
<p>事实上，计算机一直是基于精确逻辑的工作模式，任何微小的逻辑错误，都会在计算积累中不断地被放大，直到逻辑崩塌或程序崩溃，最终导致任务失败。

<p>人脑的逻辑处理则完全不同，人脑基于"贝叶斯算法"使用概率模型，通过统计的结果来得出可能性，从而创造出各种假设，并随着接收到的新信息而不断调整模型，同时又会根据最新模型连续地计算，不断逼近最真实准确的答案，所以人脑可以忽略不具有规模的异常和错误。

<p>贝叶斯算法——是根据先验概率，进行概率计算，结合客观信息，调整先验概率，以此迭代循环，从而让后期预测，不断逼近准确的客观现实。通俗地说，就是预测随着新信息而不断调整，或结论随着新证据而不断改变。例如，人脑处理语言，就是概率模型的最佳体现，显然人类语言具有很强的容错性和纠错性——什么语法错误、多意混淆、口音语调、反讽幽默等等，都可以在电光石火之间被人脑大概率的正确处理，这是计算机和编程语言所望尘莫及的，因为编程语言错一个分号，程序就会"满盘皆输"——并且在人类语言之上，人脑还可以支撑精确的推理模型。例如，人类婴儿最初学习语言，也是基于概率来实现的，即：通过不同音素的连接概率，来进行语句中字词的分隔判断——显然，在没有字形的情况下，区分字词的方法，就只能记忆音素（即最小发音单元）不同连接组合的可能性。
<p>而人类智能可以运用的推理，主要有四种：
<p>第一，演绎推理，又称逻辑推理，由一般到特殊。
<p>第二，归纳推理，由特殊到一般。
<p>第三，类比推理，由特殊到特殊，可以理解为：抽象的外推，有抽象才有类比，抽象接近本质，本质通用可以外推，通才的"学习迁移"即是运用类比。
<p>第四，溯因推理，又称反绎推理（或反向演绎），由特殊到解释，可以理解为：大脑遥远区域的长连接，以及潜意识的计算，即直觉。
<p>其中，演绎与归纳，（在数学上）是基于精确逻辑的（在人脑中是相对精确的），类比与溯因，则是基于概率统计的，而推理的根本作用就是——捕获因果，预测未来。
<p>事实上，直觉、闪念、灵感、顿悟所带来的洞见，往往就是运用类比与溯因的推理结果，其过程看似没有逻辑，实则背后是神经网络"遥远连接"所激发的信息的"自由"排列组合。
<p>显然，概率会让这种"洞见"，有时是灵光乍现，即蕴含着深刻本质的逻辑，有时则是胡说八道，即类比错误、溯因荒谬。
<p>类比——是形式不同，但逻辑相同的连接。
<p>溯因——是根据现象，寻找最可能的解释。
<p>可见，人类智能在结构与计算之上，必须要引入概率统计的工作模式，才能够展现出其强大的推理预测能力。
<p>那么，基于精确逻辑的计算机，能够基于概率统计来工作吗？
<p>深度学习领域的三位专家，在奠基性的经典教材《深度学习》（Deep Learning）中，指出："在人工智能领域，概率论主要有两种用途：首先，概率法则告诉我们，人工智能系统如何推理；其次，可以用概率和统计，从理论上分析人工智能系统的行为。……概率论，使我们能够提出不确定性的声明，以及针对不确定性的情景进行推理；而信息论，则使我们能够量化概率分布中不确定性的总量。"
<p>是的，从某种角度来看：人工智能 = 计算机 + 概率论 + 信息论 + 大数据，其中概率论就是能够让算法创造算法的机制——就如同人脑中概率模型的运作。
<p>对此，作者在《深度学习》中，这样说道："学习理论表明，机器学习算法能够在有限个训练集样本中，很好地泛化——这似乎违背一些基本的���辑原则。通常，归纳推理（即从一组有限的样本中推理出一般性的规则），在逻辑上不是很有效。因为，为了逻辑���理出一个规则去描述集合中的元素，我们必须具有集合中每个元素的信息——这是很难做到的。但在一定程度上，机器学习仅通过概率法则，就可以避免这个问题，而无须使用纯逻辑推理整个确定性的法则。最终，机器学习可以保证找到一个，在所关注的大多数样本上可能正确的规则。"
<p>那么，应用了概率，就需要接受概率的模糊性与不确定性。
<p>没有免费午餐定理（No Free Lunch Theorem）已经清楚地表明，没有最优的学习算法，特别是没有最优的正则化形式。
<p>正则化（Regularization）——是指向模型中加入某些先验的规则（如正则项，或称规则项），以减小模型的求解误差。通俗地说，就是把人类的知识，以数学的形式告诉模型。那么，没有最优正则化形式，意思就是人类的知识，没法用完美的数学形式告诉模型。
<p>因此，机器学习研究的目标，不是找一个通用学习算法，或是绝对最好的学习算法，而是理解什么样的概率分布，与人工智能获取数据的"真实世界"有关，以及什么样的学习算法，在我们所关注的数据分布上，效果最好。
<p>事实上，我们应该彻底放弃，用人类智能去寻找"算法"来"更新"人工智能，而是用人脑源源不断产生的数据，去"喂养"人工智能，然后让它从简单结构开始，向着复杂结构不断地"自我演化"——就像当初的人脑一样。
<p>例如，历史上的天才，他们对世界的认���和理解，可能还不如今天一个普通人，就是因为天才缺少了当今世界的"数据-信息"——可见，平庸 + 信息 > 天才，机器 + 数据 > 人才。
<p>那么在应用中，大多数机器学习算法都有"超参数"（Hyperparameter），它是在开始学习过程之前，需要设置值的参数，而不是通过训练，从数据中学习得到的参数，设置它可以控制算法的行为、性能与效果。通常情况下，需要人��对超参数进行优化，即给出一组"最优超参数"，以提高学习的能力与结果。
<p>换言之，我们应该是设计一个循环嵌套的学习过程，让一个学习算法为另一个学习算法，学习出"最优超参数"，而不是人工提供这个"最优超参数"。
<p>最后可见，正确的预测（或说预测的正确率），取决于信息量（信息可以消除不确定性），而信息来源于数据，没有更多的数据，就是没有更准确的预测，那么"在迭代计算中，用结构去捕获数据，进而掌控预测的概率"——这就是人工智能与人类智能的"同构演化"，即：具有同构性的两种演化。
<p>换言之，智能演化的最后一步，必然就是——万事俱备，只欠数据；而智能演化的内在动力，必然就是——成本函数，尽量最小。
<p>顺便一提，如果我们的世界，是计算机模拟的一个程序，那么这个程序的"最优超参数"——就应该是我们物理学上发现的各种"基本常数"，如：光速、普朗克常数、引力常数等等。
<h2>智能的本质</h2>
<p>前文讨论了智能的诸多层面，现在我们将从生物演化和物理规律的视角，来解释智能的本质到底是什么。
<p>首先，从生物演化角度。
<p>演化压力要求，生物体构建出趋利避害的功能，否则就会被淘汰，那么如何才能趋利避害？——首当其冲的就是，准确地预测利与害。那么如何才能准确地预测利与害？——自然是，通过智能的推理能力（即演绎、归纳、类比、溯因）。
<p>事实上，基因本来是利用神经元，来控制运动和反射的，其存在的目的仅仅是控制肌肉的运动，所以植物不需要神经元，动物才需要。
<p>而显然，运动的时机与环境信息密切相关，于是后来神经元就开始对信息进行记忆、识别、分析、预测，最终是模拟（模拟是为了更好的预测）——这个过程，也是从神经元到大脑、到人脑、再到产生智能的演化过程。
<p>换言之，是环境在促成神经系统对环境信息的模拟和预测，从而逐渐把神经系统演化成了智能系统，所以大脑是由神经元构成的神经网络。最终，基因设定了一套基础规则，即本能，然后就放手让大脑去接管几乎所有的决策与选择行为，即智能。
<p>由此可见，智能来源于对运动控制的迭代升级——它是根据环境信息制定"运动算法"的算法，或说为了应对环境，智能提高了运动对环境的反应策略——它是（凭借推理能力）对环境信息的理解（即捕获了因果关系）。
<p>一个有趣的类比是：程序环境中的——数据与行为（行为具体是指函数或方法的实现），对应了自然环境中的——信息和运动。
<p>所以，面向对象编程（Object Oriented Programming，OOP）把数据与行为"打包"，其实是符合演化模型的，从某种角度说，OOP具有分形递归的特性，即：整体可以由局部递归组合而成，且整体与局部具有自相似性——这让它可以模拟生物体的演化特性。
<p>而更宏观地看，智能是生物体在演化压力之下，不断升级的必然产物，也是无数次随机试错的偶然产物。例如，有个物种，由于基因突变获得了一个演化优势，但在一段时间后，它的"竞争者"也会演化出新的优势，来抵消它的优势，所以演化出比基因突变，更具趋利避害优势的"智能系统"，就是一种被迫"军备竞赛"般的"随机必然"。
<p>或许有人会说，基因构建的本能，也能够预测未来，动物也可以针对环境信息，做出预测性的行动反馈——但事实上，本能并没有推理，而只是做出有限模式的"套路化"反馈，即：条件反射与应激反应。
<p>因此，我们可以将智能看成是——通过推理的预测能力，即：推理能力越强，预测能力就越强，智能就越强，反之智能越弱，预测能力就越弱，推理能力也就越弱。
<p>那么，生物体通过智能最大化趋利避害之后，会怎么样呢？
<p>当然就是，高效地吃喝、不停地繁衍、长久地生存，最后还会发展出越来越先进的科技——这显然会消耗更多的能量，制造更多的熵增。
<p>其次，从物理规律角度。
<p>一个层面，熵增定律要求，局部自组织有序熵减，以推动整体更加的无序熵增，因为维持局部有序，需要注入能量，而消耗能量的过程，会在整体产生更多的无序。
<p>另一个层面，系统能量足够，就可以保持对称性（无序），能量不足就会对称性破缺（有序），如：水的能量高于冰，水的旋转对称性高于冰，水比冰更对称无序，同理水蒸气比水更对称无序。
<p>注意，直觉上我们可能会觉得，冰比水更"对称有序"——但事实上并不是这样，因为更高的对称性意味着，在更多的变换下（如旋转变换下）具有不变性，即：对称性增加了保持一切不变的操作，也就是增加了不变性，变得更无序（因为有变化才能区分排序）。
<p>那么，结合以上两个层面来看：熵增会驱使局部有序，维持有序需要注入能量，于是有序就会演化出，越来越高效的耗能系统来获取能量，而拥有足够的能量，就可以保持相关系统（即耗能系统所能够影响的系统）的对称性。
<p>那么，对称性意味着演化的可选择性，可选择性则可以通过选择权的不对称性，让系统局部从相关系统中受益，进而获得更多的能量，这又会推动局部更加的有序和耗能，最终令系统整体走向不断熵增的（正反馈）演化过程。
<p>选择权——简单来说，就是具有选择的权利，可以放弃这个权利。
<p>可选择性——简单来说，就是具有选择的选项，选项可以是选择权。
<p>类比来看：
<p>局部有序就是——人类身体（包括大脑），
<p>耗能系统就是——人类大脑（耗能最高），
<p>相关系统就是——生存环境，
<p>有对称性就是——具有智能，
<p>可选择性就是——表现智能，
<p>局部受益就是——趋利避害，
<p>综合起来就是——人脑通过智能获得趋利避害，以让人类越来越善于消耗能量，从而顺应宇宙熵增的演化。而对称性破缺产生有序，就是使用智能的过程，也就是行使选择权的过程，具体如下：
<p>在智能选择之后，系统就会进入不对称模式，此时继续向系统注入能量，系统内部就会开始结构的排列组合和远近连接，并以内部协调的方式产生新结构，从而形成更大的对称性，拥有更大的可选择性，同时也需要更多的能量，才能维持在这个状态，而这个状态就是更强大的智能——或说可以表现出更强大的智能。
<p>类比来看，使用智能可以使人脑产生新结构，而人脑的可塑性可以协调新结构，使得人脑结构具有更大的对称性，这相当于人脑神经网络拥有更多的最短连接路径，以及更多的发展可选择性（因为对称性带来更多耗能相同的选项），结果在相同耗能下，前者可以激活更多的思路，后者可以应对更多的情况，这即是增强了人类智能。
<p>而更强的智能，又可以使人脑从生存环境中获得更多的可选择性，这体现在可以看到环境中更多的可选择性（因为识别更多的对称性），以及让环境具有更多的发展可选择性（因为对环境有更多的操作），这即是趋利避害的演化最优解。
<p>可见，智能的本质，就是通过耗能维持系统对称性的能力。
<p>那么结合前文，人类智能是人脑结构复杂性的涌现，现在来看会有更进一步的理解，即：结构的复杂性在于——规模性和动态性，前者可以通过能量产生增长，后者可以通过能量产生对称，两者的结合就可以产生——复杂系统的对称性，这即是人类智能。
<p>而在构建复杂智能的过程中，最为关键的地方在于——新结构是有序，但结构的对称可以产生无序——就像圆形比三角形更加的对称（旋转对称性）、更加的无序、也拥有更多的最短连接路径。
<p>需要指出的是，结构对称，虽然在系统整体产生了结构无序，但如果这个过程，引入了新结构或剪裁出新结构，就会增加系统内部的结构有序，而这个内部有序往往会超过整体无序——所以系统结构对称，是一个耗能熵减的过程，即：
<p>系统用小的无序，换取了大的有��，结果内部更有序，整体更有序，外部更无序，环境更无序——就像一个圆球，外部（旋转）对称无序，内部（分子）不对称有序，并且是内部的有序，支撑了外部的无序。例如，健身运动，就是给身体造成——小的损伤（即小的无序，增加对称性），再利用过量修复产生——大的强健（即大的有序，增加不对称性），结果身体就会比从前更有序——当然，如果运动过度，也会使得身体更无序。例如，内部竞争，就是给公司造成——小的混乱（即小的无序，增加对称性），再利用竞争压力产生——大的创新（即大的有序，增加不对称性），结果公司就会比从前更有序——当然，如果竞争过度，也会使得公司更无序。例如，在群体中，有序意味着排位（不对称），无序意味着平等（对称），显然后者更具创造创新力——但前提条件是，群体中的个体需要具有耗能熵减的能力。
<p>按此理解，"智熵"就是通过智能，提高系统对称无序（系统局部熵减）与环境对称无序（环境整体熵增），最终推动宇宙熵增的编码能力，即：智熵 = 智能 + 熵增。
<p>而对称性的意义，就在于提供了——可选择性，即：可以利用更多的路径选项，来对抗环境压力的驱使，从而维持自身状态的不变，或向着自身有利状态的改变。
<p>显然，拥有可选择性，就可以表现出智能——就像有一个开关、多个开关、感应开关、语音开关、自定义开关、可编程开关等等，可选择性越多，就越表现出智能。
<p>而可选择性的意义，就在于选择权的不对称性，如：能量不对称，我有的选，你没的选；信息不对称，我知道怎么选，你不知道怎么选；等等——这意味着，拥有趋利避害的生存优势。例如，如果你的工作可选、生活可选、娱乐可选，你就拥有可选择性，而这些选项可以相互替代（即选谁都一样具有不变性），就形成了对称性（因为对称性的背后就是不变性），但维持这些可选择性让你保有选择权（即不对称的权利），需要你拥有能量，或恰当地使用智能。
值得指出的是，随机性也可以带来可选择性，如继承与运气——所以随机性可以创造智能，也可以在某个层面超越智能，即：随机试错具有超越迭代试错的概率。
<p>事实上，任何耗能系统，都可以因为注入能量而保持结构的对称性，从而具有可选择性，进而表现出某种智能，只不过人脑是自然界演化出的，最复杂的耗能系统，所以人类智能是自然界中，最强大的智能。例如，宇宙奇点具有对称性（高温无序），接着大爆炸之后，由于空间膨胀（的环境压力），宇宙的对称性破缺（低温有序），然后又向着无序熵增的方向演化——可见宇宙本身，就具有某种智能，它在试图维持自身处在"对称无序具有可选择性"的状态。
<p>那么归根究底，可选择性带来适应性，这是演化对智能的要求，而对称性（无序）需要注入能量，这是熵增对演化的要求。
<p>可见，适应性（演化）= 可选择性（表现智能）= 对称性（具有智能）= 有序（信息不对称） + 能量（能量不对称）——信息可以消除不确定性，有序即确定，意味着具有更多的信息。
而如果没有适应性（或适应性不足），就说明缺少对称性，也就是"有序 + 能量"中的能量不够，此时有序，就会被环境压力分解为"无序 + 能量"，其能量会被用来支撑其它"有序 + 能量"的演化，只剩下无序熵增。
<p>换言之：能量不足——会促使"有序到无序"并释放能量（即淘汰），能量足够——会促使吸收"有序到无序"释放的能量（即留存），结果永远——是"有序到无序"的熵增（即方向）。
<p>因此，智能可以看成是，熵增驱动演化的结果，而熵增就可以看成是，演化压力的压力，或说是宇宙演化的"终极压力"。
<p>最后，更抽象地看——智能只是能量流动中的一种模式，更简单地看——智能只是趋利避害中的一种模式（本能与智能是两种模式），更一般地看——智能就是获得可选择性的能力。
<h2>不同的视角</h2>
<p>人工智能，虽然来源于对人类智能的模拟，但如果模拟到了演化算法，它就会有自己的发展，并且还会反作用于人类智能本身，比如从机器学习的有效算法，去反思人类学习的神经运作。
<p>事实上，人工智能与人类智能的智能竞赛，可以倒逼我们找到自身智能奥秘的底层逻辑，因为越高级复杂的智能，其演化路径就越是狭窄的，就像人类眼睛与章鱼眼睛，是独立演化出的两种相似结构，所以人工智能与人类智能，在智能演化的道路上，最终也可能会"殊途同归"。那么，从这个角度来看，人工智能目前还不及人类智能的事情，一方面是它的智能演化才刚刚开始，另一方面则是因为人类还不够了解自己，还无法提供人工智能加速演化的关键技术。
<p>然而，如果仅从复杂结构的"连接性、动态性、随机性"来标度智能，我们会发现整个互联网就像一个人脑。
<p>其中，互联的计算网络就像是人脑的神经网络，连入网络的每台计算设备，就像是一个神经元细胞——不，其实是每个使用设备的人，才是一个神经元细胞——每个人都在贡献着数据与结构，人与人之间的连接和关系，以及数据交互的动态性和自由意志的随机性，就构成了一个"类脑"的复杂结构。
<p>换个角度来看，为什么说互联网是我们大脑的延伸，而不是"眼耳手腿"，就是因为互联网连接的是我们大脑。
<p>这样，整个互联网会演化出自己的智能吗？
<p>同理类似，一个超大规模的城市，通过其不断变化又极其繁复的交通网络与基础设施，将其中数以千万的"人类神经元"连接起来，进行信息的传递和交换，从而构成了一个"类脑"的复杂结构。
<p>这样，整个城市会演化出自己的智能吗？
<p>答案是否定的，即互联网与城市都无法产生智能，其关键原因有两点：其一，人类自身的演化，限制了人与人之间的连接——150定律（即邓巴数）表明，人类拥有稳定的社交网络人数大约是150人——而在人脑神经网络中，一个神经元与其它神经元的连接数，平均约有7000个。
其二，人脑神经元总数大约有860亿个，而全球人类总数大约只有70多亿。神经元的连接数：Do we have brain to spare
神经元的总个数：The human brain in numbers实际中，通过对不同规模的欧洲城市，其居民电话记录的大数据分析，著名理论物理学家、圣塔菲研究所前所长——杰弗里·韦斯特（Geoffrey West），在《规模》中，指出："一个普通个体的熟人模块集聚系数，近似恒定量，不会随着城市规模的变化而改变。"——这可以说是，对150定律的量化验证。
<p>可见，用"人类神经元"去构建一个"类脑结构"，不考虑别的，仅在标度上就有数量级的差距，而量变显然决定了结构的涌现与质变。
<p>由此看来，智能不仅在于结构与能量，还在于规模与尺度，也就是关乎于时间与空间——规模取决于结构的存在时间，尺度取决于结构的活动空间。
<h2>智能的涌现</h2>
<p>人脑，大约有860亿个神经元——其中，大脑皮质大约有140~160亿个，小脑大约550~700亿个。而一个神经元，大约有7000个连接，每个连接位置都有一个突触，每个突触都是一个可调节连接强度的权重，即参数——如：神经递质释放量、放电频率、放电间隔、网络同步性、活动持续性等。
<p>维基百科神经元：成年人约有100~500万亿个突触连接
<p>所以，大脑的总参数是860亿 * 7000 = 602万亿，大脑皮质的参数是140~160亿 * 7000 = 98~112万亿——而后者是直接支持人类智能的参数量——也就是说，涌现出"类人智能"的参数规模，是100万亿的数量级。
<p>但我们知道，人脑的能力，不仅在于其规模，还在于其训练的"信息质量"，即：再有天赋的大脑，如果没有高质量的"输入信息"，也就没有高质量的"输出信息"。这意味着，人工智能的模型规模，会存在边际效用递减，即在一定规模之后，必须要有高质量的"大数据"投喂，才能继续提升智能水平。
<p>那么，人类的神经元数量，为什么没有突破1000亿的数量级呢？
<p>答案是，没有必要——因为，婴儿的突触（即参数）数量在1000万亿（即10^15）的数量级，而成人则会剪裁到100~500万亿（即10^14）的数量级——可见，成人的参数量（百万亿10^14）比细胞量（千亿10^11）多3个数量级，而婴儿（千万亿10^15）则是多4个数量级——这意味着，面对地球环境，人脑的冗余性，完全够用，甚至（婴儿比成人）还剪裁掉了1个数量级（即10倍）的参数规模。
<p>有趣的不同是，一个神经元，既是"计算器"又是"方程组"，而每个连接的突触都是一个方程参数，那么一个"神经元方程组"就大约有7000个方程参数；而对比来看，人工智能的计算晶体管在"硬件芯片"上，其计算方程组在"软件程序"上。
<p>类比来看：神经元树突的凸起处，就是其它轴突信息的流入点——对应数据结构的调用接口；神经元轴突会根据周围信息的指引，不断调整延伸至其它树突的附近——对应数据结构的概率拟合；每个神经元同时连接大量不同来源与性质的信息，整合处理后产生新的融合信息——对应数据结构的复杂计算；神经元信息以不同强度与模式，向着周围进行扩散与广播——对应数据结构的网络通信。
<p>所以，或许当人工智能的模型规模，达到人类大脑皮质的规模（即100万亿参数的数量级）时，就具备了涌现出"人类通用智能"的可能性。
<p>而在此之后，提高智能水平的关键——就是投喂"高质量"的"大数据"，显然这种"高阶数据"可以来自"先喂代码、再喂数学"——因为这两者的"语言系统"，都承载了高质量的结构与关系，其内含了严谨完备自洽的逻辑性。
<p>最后，在远远超越人类智能之后，此时人工智能的智能水平想要继续攀升，再依靠人类所创造的"任何数据"，其"质"与"量"肯定是都不够了，这时候就需要人工智能可以创造自己的"高阶数据"，就像人类可以创造自己的"高阶数据"一样。

<h2>结语</h2>
<p>生命是化学的一种形式，智能是生命的一种形式（生命可以没有智能），而智能也是生命了解其自身的一种形式。
<p>但有智能并不一定就有意识，按照智能的定义（耗能、推理、预测、可选择性），人工智能已经拥有了智能，但它还不具有意识。
<p>本文的主旨是"结构主义"，即结构决定了一切，因此结构是智能的具体实现（就像程序是算法的具体实现），而这也是人工智能（或许）可以实现人类智能的根本所在。
<p>那么按此理解，意识就是结构在涌现智能之后的另一个涌现产物，可能是在于某种特殊的"回路结构"，其承载的是有关"计算的计算"——这是回路结构的结构特点。
<p>事实上，计算驱动了演化过程中的状态改变，计算的本质是用一个系统去模拟另一个系统的演化——就如颅内模拟是人脑的计算，程序模拟是机器的计算，前者是生物系统的模拟预测，后者是物理系统的模拟预测——显然，计算也是依赖于结构的，而这就是人工智能与人类智能，可以"同源计算"的演化。
<p>回到算法，从某种角度看，基因的算法是本能，人脑的算法是智能——前者源于基因结构，后者源于人脑结构，区别在于后者是一种通用算法，它可以创造其它算法，而人工智能通过数据结构与算法的相互转化，也做到了这一点。
<p>不得不说，"结构主义"为人工智能的"拟人"（即模拟人类智能），扫清了障碍，铺平了道路——甚至说，就算我们无法完全理解"智能结构黑盒"的原理，也没有关系，我们只需要将"黑盒"整体打包成一个算法，然后注入计算，任其演化——剩下的只要交给时间即可。
<p>那么，就目前而言，人工智能还只是人类智能的一种工具（或说玩具），就像数学和物理是一种工具一样，但从演化视角来看，人类又何尝不是基因的工具（或说奴隶）呢？
<p>而我们都知道，智能如果超越了某个系统，系统的规则就无法再束缚住这个智能的演化——这就是人类智能与自然系统的历史关系。
<p>因此，对于人工智能的未来，或许"结构主义"演化出的结果，是一种全新的"智能"，"祂"不仅仅是拟人的"类人智能"，更是超越人类智能系统之上的——"机器智能"，这条演化之路，或许可以被称之为——"机器主义"。
            </div>
		</div>
       </div>
	   </article>
</body>
</html>